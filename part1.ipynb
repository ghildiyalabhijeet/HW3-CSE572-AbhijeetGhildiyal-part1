{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e21cd8-9c78-4a1a-a08f-ef8e60388ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[96m\u001b[1mQ1: Objective by Method (Lower is Better)\u001b[0m\n",
      "dist_metric  final_obj_val\n",
      "     cosine   2.456332e+03\n",
      "    jaccard   6.445167e+03\n",
      "  euclidean   2.532360e+10\n",
      "\n",
      "\u001b[92m\u001b[1mQ2: In-Sample Majority Vote Accuracy\u001b[0m\n",
      "dist_metric  in_sample_acc\n",
      "     cosine         0.6139\n",
      "  euclidean         0.6018\n",
      "    jaccard         0.4480\n",
      "\n",
      "\u001b[93m\u001b[1mQ2: Predictive Accuracy (80/20 Split)\u001b[0m\n",
      "dist_metric  predict_acc\n",
      "     cosine       0.6155\n",
      "  euclidean       0.6105\n",
      "    jaccard       0.5455\n",
      "\n",
      "\u001b[91m\u001b[1mQ3: Runtime and Iteration Analysis (Early Stop)\u001b[0m\n",
      "dist_metric  loop_count  time_elapsed\n",
      "     cosine          99      9.920131\n",
      "  euclidean          32      2.401999\n",
      "    jaccard           2      0.903490\n"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "import numpy as num_py\n",
    "import pandas as pan_lib\n",
    "from sklearn.model_selection import StratifiedShuffleSplit as LayeredSplit\n",
    "\n",
    "C_CYAN = '\\033[96m'\n",
    "C_GREEN = '\\033[92m'\n",
    "C_YELLOW = '\\033[93m'\n",
    "C_RED = '\\033[91m'\n",
    "C_BOLD = '\\033[1m'\n",
    "C_END = '\\033[0m'\n",
    "\n",
    "FEAT_SRC = \"data.csv\"\n",
    "TARG_SRC = \"label.csv\"\n",
    "\n",
    "data_arr = pan_lib.read_csv(FEAT_SRC, header=None).values.astype(num_py.float64)\n",
    "target_vec = pan_lib.read_csv(TARG_SRC, header=None).values.squeeze().astype(int)\n",
    "\n",
    "n_grp = num_py.unique(target_vec).size\n",
    "pos_adj = max(0.0, -data_arr.min())\n",
    "data_adj = data_arr + pos_adj\n",
    "TOL = 1e-12\n",
    "\n",
    "def calc_vec_len(mat: num_py.ndarray) -> num_py.ndarray:\n",
    "    \"\"\"Calculates row-wise vector norms.\"\"\"\n",
    "    return num_py.sqrt((mat * mat).sum(axis=1, keepdims=True)) + TOL\n",
    "\n",
    "def pdist_sq_euc(m1: num_py.ndarray, m2: num_py.ndarray) -> num_py.ndarray:\n",
    "    \"\"\"Pairwise squared Euclidean distance.\"\"\"\n",
    "    m1_sq = (m1 * m1).sum(axis=1, keepdims=True)\n",
    "    m2_sq = (m2 * m2).sum(axis=1)[None, :]\n",
    "    dist_matrix = m1_sq + m2_sq - 2.0 * (m1 @ m2.T)\n",
    "    return num_py.maximum(dist_matrix, 0.0)\n",
    "\n",
    "def pdist_cos_dist(m1: num_py.ndarray, m2: num_py.ndarray) -> num_py.ndarray:\n",
    "    \"\"\"Pairwise 1 - Cosine Similarity.\"\"\"\n",
    "    m1_norm = m1 / calc_vec_len(m1)\n",
    "    m2_norm = m2 / calc_vec_len(m2)\n",
    "    sim_matrix = m1_norm @ m2_norm.T\n",
    "    sim_matrix = num_py.clip(sim_matrix, -1.0, 1.0)\n",
    "    dist_matrix = 1.0 - sim_matrix\n",
    "    return num_py.clip(dist_matrix, 0.0, 2.0)\n",
    "\n",
    "def pdist_gen_jac(m1: num_py.ndarray, m2: num_py.ndarray) -> num_py.ndarray:\n",
    "    \"\"\"Pairwise 1 - Generalized Jaccard.\"\"\"\n",
    "    n_rows, k_rows = m1.shape[0], m2.shape[0]\n",
    "    res_mat = num_py.empty((n_rows, k_rows), dtype=num_py.float64)\n",
    "    for idx in range(k_rows):\n",
    "        numerator = num_py.minimum(m1, m2[idx:idx+1]).sum(axis=1) + TOL\n",
    "        denominator = num_py.maximum(m1, m2[idx:idx+1]).sum(axis=1) + TOL\n",
    "        res_mat[:, idx] = 1.0 - (numerator / denominator)\n",
    "    res_mat = num_py.clip(res_mat, 0.0, 1.0)\n",
    "    res_mat[~num_py.isfinite(res_mat)] = 0.0\n",
    "    return res_mat\n",
    "\n",
    "def get_dist_mat(m1: num_py.ndarray, m2: num_py.ndarray, m_type: str) -> num_py.ndarray:\n",
    "    \"\"\"Dispatcher for pairwise distance calculation.\"\"\"\n",
    "    if m_type == \"euclidean\":\n",
    "        d_mat = pdist_sq_euc(m1, m2)\n",
    "    elif m_type == \"cosine\":\n",
    "        d_mat = pdist_cos_dist(m1, m2)\n",
    "    elif m_type == \"jaccard\":\n",
    "        d_mat = pdist_gen_jac(m1, m2)\n",
    "    else:\n",
    "        raise ValueError(\"m_type must be 'euclidean', 'cosine', or 'jaccard'\")\n",
    "    d_mat[~num_py.isfinite(d_mat)] = 0.0\n",
    "    return num_py.maximum(d_mat, 0.0)\n",
    "\n",
    "def update_centers(d_arr: num_py.ndarray, assigns: num_py.ndarray, n_grp: int,\n",
    "                     m_type: str, rand_gen: num_py.random.Generator) -> num_py.ndarray:\n",
    "    \"\"\"Recomputes cluster centers based on current assignments.\"\"\"\n",
    "    n_feat = d_arr.shape[1]\n",
    "    centers = num_py.empty((n_grp, n_feat), dtype=num_py.float64)\n",
    "    for grp_idx in range(n_grp):\n",
    "        grp_mask = (assigns == grp_idx)\n",
    "        if not num_py.any(grp_mask):\n",
    "            centers[grp_idx] = d_arr[rand_gen.integers(0, d_arr.shape[0])]\n",
    "            continue\n",
    "        if m_type == \"cosine\":\n",
    "            vec_sum = d_arr[grp_mask].sum(axis=0)\n",
    "            centers[grp_idx] = vec_sum / (num_py.linalg.norm(vec_sum) + TOL)\n",
    "        else:\n",
    "            centers[grp_idx] = d_arr[grp_mask].mean(axis=0)\n",
    "    return centers\n",
    "\n",
    "def init_centers_pp(d_arr: num_py.ndarray, n_grp: int, m_type: str, \n",
    "                      rand_gen: num_py.random.Generator) -> num_py.ndarray:\n",
    "    \"\"\"Initializes centers using K-Means++.\"\"\"\n",
    "    n_pts, n_dim = d_arr.shape\n",
    "    if n_grp > n_pts:\n",
    "        raise ValueError(f\"n_grp={n_grp} cannot exceed n_pts={n_pts}.\")\n",
    "    \n",
    "    centers = num_py.empty((n_grp, n_dim), dtype=num_py.float64)\n",
    "    \n",
    "    first_idx = rand_gen.integers(0, n_pts)\n",
    "    centers[0] = d_arr[first_idx]\n",
    "    \n",
    "    min_dists = get_dist_mat(d_arr, centers[:1], m_type).squeeze()\n",
    "    min_dists = num_py.maximum(min_dists, 0.0)\n",
    "    \n",
    "    for i_center in range(1, n_grp):\n",
    "        dist_probs = num_py.maximum(min_dists.copy(), 0.0)\n",
    "        prob_sum = dist_probs.sum()\n",
    "        \n",
    "        if not num_py.isfinite(prob_sum) or prob_sum <= 0.0:\n",
    "            next_idx = rand_gen.integers(0, n_pts)\n",
    "        else:\n",
    "            dist_probs = dist_probs / prob_sum\n",
    "            dist_probs = num_py.maximum(dist_probs, 0.0)\n",
    "            s_check = dist_probs.sum()\n",
    "            if s_check <= 0.0 or not num_py.isfinite(s_check):\n",
    "                next_idx = rand_gen.integers(0, n_pts)\n",
    "            else:\n",
    "                dist_probs = dist_probs / s_check\n",
    "                next_idx = rand_gen.choice(n_pts, p=dist_probs)\n",
    "        \n",
    "        centers[i_center] = d_arr[next_idx]\n",
    "        new_dists = get_dist_mat(d_arr, centers[i_center:i_center+1], m_type).squeeze()\n",
    "        new_dists = num_py.maximum(new_dists, 0.0)\n",
    "        min_dists = num_py.minimum(min_dists, new_dists)\n",
    "        \n",
    "    return centers\n",
    "\n",
    "def run_cluster_algo(d_arr: num_py.ndarray,\n",
    "                       n_grp: int,\n",
    "                       m_type: str = \"euclidean\",\n",
    "                       max_loops: int = 200,\n",
    "                       rand_seed: int = 0,\n",
    "                       stop_on_no_move: bool = True,\n",
    "                       stop_on_obj_rise: bool = True) -> dict:\n",
    "    \"\"\"Performs K-Means clustering.\"\"\"\n",
    "    rand_gen = num_py.random.default_rng(rand_seed)\n",
    "    centers = init_centers_pp(d_arr, n_grp, m_type, rand_gen)\n",
    "    \n",
    "    obj_history = []\n",
    "    start_t = tm.time()\n",
    "    loop_num = 0\n",
    "    \n",
    "    for loop_num in range(1, max_loops + 1):\n",
    "        dist_mat = get_dist_mat(d_arr, centers, m_type)\n",
    "        assignments = dist_mat.argmin(axis=1)\n",
    "        \n",
    "        curr_obj = float(dist_mat[num_py.arange(d_arr.shape[0]), assignments].sum())\n",
    "        obj_history.append(curr_obj)\n",
    "        \n",
    "        new_centers = update_centers(d_arr, assignments, n_grp, m_type, rand_gen)\n",
    "        \n",
    "        is_converged = stop_on_no_move and num_py.allclose(new_centers, centers, rtol=1e-7, atol=1e-9)\n",
    "        is_worse = stop_on_obj_rise and (loop_num > 1) and (obj_history[-1] > obj_history[-2] + TOL)\n",
    "        \n",
    "        centers = new_centers\n",
    "        \n",
    "        if is_converged or is_worse:\n",
    "            break\n",
    "            \n",
    "    end_t = tm.time()\n",
    "    \n",
    "    return {\n",
    "        \"centers\": centers,\n",
    "        \"assignments\": assignments,\n",
    "        \"final_obj\": obj_history[-1],\n",
    "        \"obj_hist\": obj_history,\n",
    "        \"total_loops\": loop_num,\n",
    "        \"exec_time\": end_t - start_t,\n",
    "    }\n",
    "\n",
    "def get_cluster_label_map(assigns: num_py.ndarray, targets: num_py.ndarray, n_grp: int) -> dict:\n",
    "    \"\"\"Maps cluster index to the majority true label within that cluster.\"\"\"\n",
    "    label_map = {}\n",
    "    for grp_idx in range(n_grp):\n",
    "        grp_mask = (assigns == grp_idx)\n",
    "        if not num_py.any(grp_mask):\n",
    "            label_map[grp_idx] = None\n",
    "        else:\n",
    "            uniq_labels, label_counts = num_py.unique(targets[grp_mask], return_counts=True)\n",
    "            label_map[grp_idx] = uniq_labels[label_counts.argmax()]\n",
    "    return label_map\n",
    "\n",
    "def calc_in_sample_acc(assigns: num_py.ndarray, targets: num_py.ndarray, n_grp: int) -> float:\n",
    "    \"\"\"Calculates in-sample accuracy using the majority map.\"\"\"\n",
    "    c_map = get_cluster_label_map(assigns, targets, n_grp)\n",
    "    pred_vec = num_py.array([c_map[lab] for lab in assigns])\n",
    "    valid_mask = pred_vec != None\n",
    "    return float((pred_vec[valid_mask] == targets[valid_mask]).mean())\n",
    "\n",
    "def assign_clusters(new_data: num_py.ndarray, centers: num_py.ndarray, m_type: str) -> num_py.ndarray:\n",
    "    \"\"\"Assigns new data points to the closest cluster centers.\"\"\"\n",
    "    dist_mat = get_dist_mat(new_data, centers, m_type)\n",
    "    return dist_mat.argmin(axis=1)\n",
    "\n",
    "R_STATE = 42\n",
    "dist_types = [\"euclidean\", \"cosine\", \"jaccard\"]\n",
    "data_map = {\"euclidean\": data_arr, \"cosine\": data_arr, \"jaccard\": data_adj}\n",
    "\n",
    "res1_list = []\n",
    "for m_name in dist_types:\n",
    "    run_result = run_cluster_algo(data_map[m_name], n_grp, m_type=m_name, max_loops=200, rand_seed=R_STATE)\n",
    "    res1_list.append({\"dist_metric\": m_name, \"final_obj_val\": run_result[\"final_obj\"]})\n",
    "\n",
    "res1_df = pan_lib.DataFrame(res1_list).sort_values(\"final_obj_val\")\n",
    "print(f\"\\n{C_CYAN}{C_BOLD}Q1: Objective by Method (Lower is Better){C_END}\")\n",
    "print(res1_df.to_string(index=False))\n",
    "\n",
    "res2_in_list = []\n",
    "for m_name in dist_types:\n",
    "    run_result = run_cluster_algo(data_map[m_name], n_grp, m_type=m_name, max_loops=200, rand_seed=R_STATE)\n",
    "    accuracy_val = calc_in_sample_acc(run_result[\"assignments\"], target_vec, n_grp)\n",
    "    res2_in_list.append({\"dist_metric\": m_name, \"in_sample_acc\": accuracy_val})\n",
    "\n",
    "res2_in_df = pan_lib.DataFrame(res2_in_list).sort_values(\"in_sample_acc\", ascending=False)\n",
    "\n",
    "splitter = LayeredSplit(n_splits=1, test_size=0.2, random_state=R_STATE)\n",
    "(tr_idx, te_idx) = next(splitter.split(data_arr, target_vec))\n",
    "\n",
    "data_train, target_train = data_arr[tr_idx], target_vec[tr_idx]\n",
    "data_test, target_test = data_arr[te_idx], target_vec[te_idx]\n",
    "\n",
    "pos_adj_train = max(0.0, -data_train.min())\n",
    "data_train_adj = data_train + pos_adj_train  \n",
    "data_test_adj = data_test + pos_adj_train\n",
    "\n",
    "train_data_map = {\"euclidean\": data_train, \"cosine\": data_train, \"jaccard\": data_train_adj}\n",
    "test_data_map = {\"euclidean\": data_test, \"cosine\": data_test, \"jaccard\": data_test_adj}\n",
    "\n",
    "res2_pred_list = []\n",
    "for m_name in dist_types:\n",
    "    run_result = run_cluster_algo(train_data_map[m_name], n_grp, m_type=m_name, max_loops=200, rand_seed=R_STATE)\n",
    "    c_map = get_cluster_label_map(run_result[\"assignments\"], target_train, n_grp)\n",
    "    \n",
    "    test_assigns = assign_clusters(test_data_map[m_name], run_result[\"centers\"], m_name)\n",
    "    pred_labels = num_py.array([c_map.get(lbl, None) for lbl in test_assigns])\n",
    "    \n",
    "    valid_mask = pred_labels != None\n",
    "    accuracy_val = float((pred_labels[valid_mask] == target_test[valid_mask]).mean())\n",
    "    res2_pred_list.append({\"dist_metric\": m_name, \"predict_acc\": accuracy_val})\n",
    "\n",
    "res2_pred_df = pan_lib.DataFrame(res2_pred_list).sort_values(\"predict_acc\", ascending=False)\n",
    "\n",
    "print(f\"\\n{C_GREEN}{C_BOLD}Q2: In-Sample Majority Vote Accuracy{C_END}\")\n",
    "print(res2_in_df.to_string(index=False))\n",
    "print(f\"\\n{C_YELLOW}{C_BOLD}Q2: Predictive Accuracy (80/20 Split){C_END}\")\n",
    "print(res2_pred_df.to_string(index=False))\n",
    "\n",
    "res3_list = []\n",
    "for m_name in dist_types:\n",
    "    run_result = run_cluster_algo(\n",
    "        data_map[m_name], n_grp, m_type=m_name, max_loops=500, rand_seed=R_STATE,\n",
    "        stop_on_no_move=True, stop_on_obj_rise=True\n",
    "    )\n",
    "    res3_list.append({\n",
    "        \"dist_metric\": m_name, \n",
    "        \"loop_count\": run_result[\"total_loops\"], \n",
    "        \"time_elapsed\": run_result[\"exec_time\"]\n",
    "    })\n",
    "\n",
    "res3_df = pan_lib.DataFrame(res3_list).sort_values(\"loop_count\", ascending=False)\n",
    "print(f\"\\n{C_RED}{C_BOLD}Q3: Runtime and Iteration Analysis (Early Stop){C_END}\")\n",
    "print(res3_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a0b84c-85ee-4656-9c98-06bb5f9defcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[96m\u001b[1mQ4: Termination Rule Comparison\u001b[0m\n",
      "         term_rule dist_metric  final_obj_val  loop_count\n",
      "          max-iter      cosine   2.456342e+03         100\n",
      "          max-iter     jaccard   6.017834e+03         100\n",
      "          max-iter   euclidean   2.532360e+10         100\n",
      "         no-change      cosine   2.456339e+03         105\n",
      "         no-change     jaccard   6.017834e+03          30\n",
      "         no-change   euclidean   2.532360e+10          32\n",
      "objective-increase      cosine   2.456332e+03          99\n",
      "objective-increase     jaccard   6.445167e+03           2\n",
      "objective-increase   euclidean   2.532360e+10         500\n"
     ]
    }
   ],
   "source": [
    "term_criteria = [\n",
    "    (\"no-change\",          dict(stop_on_no_move=True,  stop_on_obj_rise=False, max_loops=500)),\n",
    "    (\"objective-increase\", dict(stop_on_no_move=False, stop_on_obj_rise=True,  max_loops=500)),\n",
    "    (\"max-iter\",           dict(stop_on_no_move=False, stop_on_obj_rise=False, max_loops=100)),\n",
    "]\n",
    "\n",
    "res4_list = []\n",
    "for name, config in term_criteria:\n",
    "    for m_name in dist_types:\n",
    "        run_result = run_cluster_algo(\n",
    "            data_map[m_name], n_grp, m_type=m_name, rand_seed=R_STATE,\n",
    "            max_loops=config[\"max_loops\"],\n",
    "            stop_on_no_move=config[\"stop_on_no_move\"],\n",
    "            stop_on_obj_rise=config[\"stop_on_obj_rise\"],\n",
    "        )\n",
    "        res4_list.append({\n",
    "            \"term_rule\": name,\n",
    "            \"dist_metric\": m_name,\n",
    "            \"final_obj_val\": run_result[\"final_obj\"],\n",
    "            \"loop_count\": run_result[\"total_loops\"],\n",
    "        })\n",
    "\n",
    "res4_df = pan_lib.DataFrame(res4_list).sort_values([\"term_rule\", \"final_obj_val\"])\n",
    "\n",
    "print(f\"\\n{C_CYAN}{C_BOLD}Q4: Termination Rule Comparison{C_END}\")\n",
    "print(res4_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e622d28-d12d-4e9b-89f1-a82d7436d9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
